{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a30b63-f29d-4064-81be-35b7576a37a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Imports\n",
    "# Here we import the required libraries\n",
    "\n",
    "# %% [code]\n",
    "!pip install torchsummary\n",
    "!pip install efficientnet_pytorch\n",
    "\n",
    "# %% [code]\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(32)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Dataset and preprocessing\n",
    "\n",
    "# %% [code]\n",
    "# Configuración de rutas y parámetros\n",
    "DATA_DIR = '/kaggle/input/aa-iv-2025-i-object-localization/'\n",
    "WORK_DIR = '/kaggle/working'\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (255, 400)  # (height, width)\n",
    "h_real, w_real = 720, 1280\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(osp.join(DATA_DIR, \"train.csv\"))\n",
    "obj2id = {'f16':0, 'cougar':1, 'chinook':2, 'ah64':3, 'f15':4, 'seahawk':5}\n",
    "id2obj = {v:k for k,v in obj2id.items()}\n",
    "df[\"class_id\"] = df[\"class\"].map(obj2id)\n",
    "\n",
    "# Normalizar bboxes\n",
    "df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(h_real, axis=0)\n",
    "df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(w_real, axis=0)\n",
    "\n",
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, stratify=df['class_id'], test_size=0.25, random_state=42)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Custom CNN Backbone\n",
    "\n",
    "# %% [code]\n",
    "class CustomBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((7, 7)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model with multiple backbone options\n",
    "\n",
    "# %% [code]\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, backbone_type='custom', n_classes=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Selección de backbone\n",
    "        if backbone_type == 'resnet':\n",
    "            self.backbone = resnet50(pretrained=True)\n",
    "            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "            self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "            out_features = 2048\n",
    "        elif backbone_type == 'efficientnet':\n",
    "            self.backbone = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "            self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "            out_features = 1280\n",
    "        else:  # Custom\n",
    "            self.backbone = CustomBackbone()\n",
    "            out_features = 256 * 7 * 7\n",
    "        \n",
    "        # Cabezas\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(out_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(out_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        if isinstance(self.backbone, CustomBackbone):\n",
    "            features = features.view(features.size(0), -1)\n",
    "        else:\n",
    "            features = self.pool(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            \n",
    "        return {\n",
    "            'class_id': self.cls_head(features),\n",
    "            'bbox': self.reg_head(features)\n",
    "        }\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Augmentation Strategies\n",
    "\n",
    "# %% [code]\n",
    "# Estrategia 1 - Transformaciones básicas\n",
    "aug_strategy1 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='albumentations'))\n",
    "\n",
    "# Estrategia 2 - Transformaciones más agresivas\n",
    "aug_strategy2 = A.Compose([\n",
    "    A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "    A.RandomShadow(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='albumentations'))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Dataset and Transforms\n",
    "\n",
    "# %% [code]\n",
    "class MilitaryDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None, output_size=IMG_SIZE):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row['filename'])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.output_size:\n",
    "            image = cv2.resize(image, (self.output_size[1], self.output_size[0]))\n",
    "        \n",
    "        bbox = row[['xmin', 'ymin', 'xmax', 'ymax']].values.astype(np.float32)\n",
    "        class_id = row['class_id']\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, bboxes=[bbox])\n",
    "            image = transformed['image']\n",
    "            bbox = transformed['bboxes'][0]\n",
    "            \n",
    "        image = image.transpose(2, 0, 1).astype(np.float32) / 255.0\n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),\n",
    "            'bbox': torch.tensor(bbox, dtype=torch.float),\n",
    "            'class_id': torch.tensor(class_id, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training Loop\n",
    "\n",
    "# %% [code]\n",
    "def train_model(backbone_type, aug_strategy, num_epochs=10):\n",
    "    # Datasets\n",
    "    train_dataset = MilitaryDataset(\n",
    "        train_df, \n",
    "        osp.join(DATA_DIR, \"images/images\"), \n",
    "        transform=aug_strategy,\n",
    "        output_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    val_dataset = MilitaryDataset(\n",
    "        val_df,\n",
    "        osp.join(DATA_DIR, \"images/images\"),\n",
    "        output_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4)\n",
    "    \n",
    "    # Model\n",
    "    model = MultiTaskModel(backbone_type=backbone_type).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    reg_criterion = nn.SmoothL1Loss()\n",
    "    \n",
    "    best_iou = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            images = batch['image'].to(device)\n",
    "            bboxes = batch['bbox'].to(device)\n",
    "            classes = batch['class_id'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            cls_loss = cls_criterion(outputs['class_id'], classes)\n",
    "            reg_loss = reg_criterion(outputs['bbox'], bboxes)\n",
    "            loss = cls_loss + reg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_cls_correct = 0\n",
    "        val_iou = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                bboxes = batch['bbox'].to(device)\n",
    "                classes = batch['class_id'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Classification\n",
    "                pred_classes = outputs['class_id'].argmax(dim=1)\n",
    "                val_cls_correct += (pred_classes == classes).sum().item()\n",
    "                \n",
    "                # Regression (IoU)\n",
    "                pred_boxes = outputs['bbox'].cpu().numpy()\n",
    "                true_boxes = bboxes.cpu().numpy()\n",
    "                iou = calculate_batch_iou(pred_boxes, true_boxes)\n",
    "                val_iou += iou * images.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        val_acc = val_cls_correct / len(val_dataset)\n",
    "        val_iou = val_iou / len(val_dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            torch.save(model.state_dict(), f\"best_model_{backbone_type}.pth\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Evaluation Metrics\n",
    "\n",
    "# %% [code]\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    return inter_area / (area1 + area2 - inter_area + 1e-6)\n",
    "\n",
    "def calculate_batch_iou(pred_boxes, true_boxes):\n",
    "    ious = []\n",
    "    for pred, true in zip(pred_boxes, true_boxes):\n",
    "        pred = pred * [w_real, h_real, w_real, h_real]\n",
    "        true = true * [w_real, h_real, w_real, h_real]\n",
    "        ious.append(calculate_iou(pred, true))\n",
    "    return np.mean(ious)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Entrenamiento Comparativo\n",
    "\n",
    "# %% [code]\n",
    "backbones = ['custom', 'resnet', 'efficientnet']\n",
    "aug_strategies = [aug_strategy1, aug_strategy2]\n",
    "\n",
    "for backbone in backbones:\n",
    "    for strategy in aug_strategies:\n",
    "        print(f\"\\nTraining with {backbone} and augmentation strategy\")\n",
    "        model = train_model(backbone_type=backbone, aug_strategy=strategy, num_epochs=15)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Generación de Submission\n",
    "\n",
    "# %% [code]\n",
    "def create_submission(model_path, backbone_type):\n",
    "    model = MultiTaskModel(backbone_type=backbone_type)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    test_df = pd.read_csv(osp.join(DATA_DIR, \"test.csv\"))\n",
    "    test_dataset = MilitaryDataset(\n",
    "        test_df,\n",
    "        osp.join(DATA_DIR, \"images/images\"),\n",
    "        output_size=IMG_SIZE\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            pred_classes = outputs['class_id'].argmax(dim=1).cpu().numpy()\n",
    "            pred_boxes = outputs['bbox'].cpu().numpy()\n",
    "            \n",
    "            for filename, cls, box in zip(batch['filename'], pred_classes, pred_boxes):\n",
    "                all_preds.append({\n",
    "                    'filename': filename,\n",
    "                    'class': id2obj[cls],\n",
    "                    'xmin': max(0, int(box[0] * w_real)),\n",
    "                    'ymin': max(0, int(box[1] * h_real)),\n",
    "                    'xmax': min(w_real, int(box[2] * w_real)),\n",
    "                    'ymax': min(h_real, int(box[3] * h_real))\n",
    "                })\n",
    "    \n",
    "    submission_df = pd.DataFrame(all_preds)\n",
    "    submission_df = submission_df[['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax']]\n",
    "    submission_df.to_csv(f'submission_{backbone_type}.csv', index=False)\n",
    "    return submission_df\n",
    "\n",
    "# Generar submissions para todos los modelos\n",
    "for backbone in backbones:\n",
    "    create_submission(f\"best_model_{backbone}.pth\", backbone_type=backbone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
