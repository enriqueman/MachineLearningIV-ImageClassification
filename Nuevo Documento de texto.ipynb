# %% [markdown]
# # Imports
# Here we import the required libraries

# %% [code]
!pip install torchsummary
!pip install efficientnet_pytorch

# %% [code]
import numpy as np
import pandas as pd
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchsummary import summary
import albumentations as A
from sklearn.model_selection import train_test_split
from efficientnet_pytorch import EfficientNet
from torchvision.models import resnet50
from tqdm import tqdm
import cv2
from PIL import Image
import matplotlib.pyplot as plt

# Set device
device = 'cuda' if torch.cuda.is_available() else 'cpu'
torch.manual_seed(32)

# %% [markdown]
# ## Dataset and preprocessing

# %% [code]
# Configuración de rutas y parámetros
DATA_DIR = '/kaggle/input/aa-iv-2025-i-object-localization/'
WORK_DIR = '/kaggle/working'
BATCH_SIZE = 32
IMG_SIZE = (255, 400)  # (height, width)
h_real, w_real = 720, 1280

# Cargar datos
df = pd.read_csv(osp.join(DATA_DIR, "train.csv"))
obj2id = {'f16':0, 'cougar':1, 'chinook':2, 'ah64':3, 'f15':4, 'seahawk':5}
id2obj = {v:k for k,v in obj2id.items()}
df["class_id"] = df["class"].map(obj2id)

# Normalizar bboxes
df[["ymin", "ymax"]] = df[["ymin", "ymax"]].div(h_real, axis=0)
df[["xmin", "xmax"]] = df[["xmin", "xmax"]].div(w_real, axis=0)

# Split dataset
train_df, val_df = train_test_split(df, stratify=df['class_id'], test_size=0.25, random_state=42)

# %% [markdown]
# ## Custom CNN Backbone

# %% [code]
class CustomBackbone(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((7, 7)),
            nn.Flatten()
        )
        
    def forward(self, x):
        return self.features(x)

# %% [markdown]
# ## Model with multiple backbone options

# %% [code]
class MultiTaskModel(nn.Module):
    def __init__(self, backbone_type='custom', n_classes=6):
        super().__init__()
        
        # Selección de backbone
        if backbone_type == 'resnet':
            self.backbone = resnet50(pretrained=True)
            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])
            self.pool = nn.AdaptiveAvgPool2d((1,1))
            out_features = 2048
        elif backbone_type == 'efficientnet':
            self.backbone = EfficientNet.from_pretrained('efficientnet-b0')
            self.pool = nn.AdaptiveAvgPool2d((1,1))
            out_features = 1280
        else:  # Custom
            self.backbone = CustomBackbone()
            out_features = 256 * 7 * 7
        
        # Cabezas
        self.cls_head = nn.Sequential(
            nn.Linear(out_features, 1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, n_classes)
        )
        
        self.reg_head = nn.Sequential(
            nn.Linear(out_features, 1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 4),
            nn.Sigmoid()
        )

    def forward(self, x):
        features = self.backbone(x)
        if isinstance(self.backbone, CustomBackbone):
            features = features.view(features.size(0), -1)
        else:
            features = self.pool(features)
            features = features.view(features.size(0), -1)
            
        return {
            'class_id': self.cls_head(features),
            'bbox': self.reg_head(features)
        }

# %% [markdown]
# ## Data Augmentation Strategies

# %% [code]
# Estrategia 1 - Transformaciones básicas
aug_strategy1 = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=30, p=0.5),
    A.RandomBrightnessContrast(p=0.2),
], bbox_params=A.BboxParams(format='albumentations'))

# Estrategia 2 - Transformaciones más agresivas
aug_strategy2 = A.Compose([
    A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),
    A.RandomShadow(p=0.2),
], bbox_params=A.BboxParams(format='albumentations'))

# %% [markdown]
# ## Dataset and Transforms

# %% [code]
class MilitaryDataset(Dataset):
    def __init__(self, df, root_dir, transform=None, output_size=IMG_SIZE):
        self.df = df
        self.root_dir = root_dir
        self.transform = transform
        self.output_size = output_size

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.root_dir, row['filename'])
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if self.output_size:
            image = cv2.resize(image, (self.output_size[1], self.output_size[0]))
        
        bbox = row[['xmin', 'ymin', 'xmax', 'ymax']].values.astype(np.float32)
        class_id = row['class_id']
        
        if self.transform:
            transformed = self.transform(image=image, bboxes=[bbox])
            image = transformed['image']
            bbox = transformed['bboxes'][0]
            
        image = image.transpose(2, 0, 1).astype(np.float32) / 255.0
        return {
            'image': torch.tensor(image, dtype=torch.float),
            'bbox': torch.tensor(bbox, dtype=torch.float),
            'class_id': torch.tensor(class_id, dtype=torch.long)
        }

# %% [markdown]
# ## Training Loop

# %% [code]
def train_model(backbone_type, aug_strategy, num_epochs=10):
    # Datasets
    train_dataset = MilitaryDataset(
        train_df, 
        osp.join(DATA_DIR, "images/images"), 
        transform=aug_strategy,
        output_size=IMG_SIZE
    )
    
    val_dataset = MilitaryDataset(
        val_df,
        osp.join(DATA_DIR, "images/images"),
        output_size=IMG_SIZE
    )
    
    # DataLoaders
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4)
    
    # Model
    model = MultiTaskModel(backbone_type=backbone_type).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    cls_criterion = nn.CrossEntropyLoss()
    reg_criterion = nn.SmoothL1Loss()
    
    best_iou = 0.0
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        
        for batch in tqdm(train_loader):
            images = batch['image'].to(device)
            bboxes = batch['bbox'].to(device)
            classes = batch['class_id'].to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            
            cls_loss = cls_criterion(outputs['class_id'], classes)
            reg_loss = reg_criterion(outputs['bbox'], bboxes)
            loss = cls_loss + reg_loss
            
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        # Validation
        model.eval()
        val_cls_correct = 0
        val_iou = 0.0
        with torch.no_grad():
            for batch in val_loader:
                images = batch['image'].to(device)
                bboxes = batch['bbox'].to(device)
                classes = batch['class_id'].to(device)
                
                outputs = model(images)
                
                # Classification
                pred_classes = outputs['class_id'].argmax(dim=1)
                val_cls_correct += (pred_classes == classes).sum().item()
                
                # Regression (IoU)
                pred_boxes = outputs['bbox'].cpu().numpy()
                true_boxes = bboxes.cpu().numpy()
                iou = calculate_batch_iou(pred_boxes, true_boxes)
                val_iou += iou * images.size(0)
        
        avg_loss = total_loss / len(train_loader)
        val_acc = val_cls_correct / len(val_dataset)
        val_iou = val_iou / len(val_dataset)
        
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"Train Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | Val IoU: {val_iou:.4f}")
        
        if val_iou > best_iou:
            best_iou = val_iou
            torch.save(model.state_dict(), f"best_model_{backbone_type}.pth")
    
    return model

# %% [markdown]
# ## Evaluation Metrics

# %% [code]
def calculate_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    inter_area = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    return inter_area / (area1 + area2 - inter_area + 1e-6)

def calculate_batch_iou(pred_boxes, true_boxes):
    ious = []
    for pred, true in zip(pred_boxes, true_boxes):
        pred = pred * [w_real, h_real, w_real, h_real]
        true = true * [w_real, h_real, w_real, h_real]
        ious.append(calculate_iou(pred, true))
    return np.mean(ious)

# %% [markdown]
# ## Entrenamiento Comparativo

# %% [code]
backbones = ['custom', 'resnet', 'efficientnet']
aug_strategies = [aug_strategy1, aug_strategy2]

for backbone in backbones:
    for strategy in aug_strategies:
        print(f"\nTraining with {backbone} and augmentation strategy")
        model = train_model(backbone_type=backbone, aug_strategy=strategy, num_epochs=15)

# %% [markdown]
# ## Generación de Submission

# %% [code]
def create_submission(model_path, backbone_type):
    model = MultiTaskModel(backbone_type=backbone_type)
    model.load_state_dict(torch.load(model_path))
    model.to(device).eval()
    
    test_df = pd.read_csv(osp.join(DATA_DIR, "test.csv"))
    test_dataset = MilitaryDataset(
        test_df,
        osp.join(DATA_DIR, "images/images"),
        output_size=IMG_SIZE
    )
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
    
    all_preds = []
    with torch.no_grad():
        for batch in test_loader:
            images = batch['image'].to(device)
            outputs = model(images)
            
            pred_classes = outputs['class_id'].argmax(dim=1).cpu().numpy()
            pred_boxes = outputs['bbox'].cpu().numpy()
            
            for filename, cls, box in zip(batch['filename'], pred_classes, pred_boxes):
                all_preds.append({
                    'filename': filename,
                    'class': id2obj[cls],
                    'xmin': max(0, int(box[0] * w_real)),
                    'ymin': max(0, int(box[1] * h_real)),
                    'xmax': min(w_real, int(box[2] * w_real)),
                    'ymax': min(h_real, int(box[3] * h_real))
                })
    
    submission_df = pd.DataFrame(all_preds)
    submission_df = submission_df[['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax']]
    submission_df.to_csv(f'submission_{backbone_type}.csv', index=False)
    return submission_df

# Generar submissions para todos los modelos
for backbone in backbones:
    create_submission(f"best_model_{backbone}.pth", backbone_type=backbone)